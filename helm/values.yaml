global:
  namespace: data-platform

zookeeper:
  enabled: true
  image: confluentinc/cp-zookeeper
  tag: "7.5.1"
  port: 2181

kafka:
  enabled: true
  image: confluentinc/cp-kafka
  tag: "7.5.1"
  replicas: 1
  port: 9092
  zookeeperConnect: "zookeeper:2181"
  autoCreateTopics: true

kafdrop:
  enabled: true
  image: obsidiandynamics/kafdrop
  tag: latest
  nodePort: 30090

kafkaProducer:
  enabled: true
  image: kafka-producer
  tag: latest
  pullPolicy: Never
  topic: orders
  bootstrapServers: "kafka:9092"

minio:
  enabled: true
  image: minio/minio
  tag: latest
  accessKey: admin
  secretKey: password
  apiPort: 9000
  consolePort: 9001
  apiNodePort: 31002
  consoleNodePort: 31001
  defaultBucket: warehouse

hiveMetastore:
  enabled: true
  image: iceberg-hms
  tag: latest
  pullPolicy: Never
  port: 9083
  warehousePath: "s3a://warehouse/"

flink:
  enabled: true
  image: thesis-flink
  tag: latest
  pullPolicy: Never

  jobManager:
    replicas: 1
    port: 8081
    nodePort: 31080

  taskManager:
    replicas: 2

  sqlJobs:
    enabled: true
    multiStatementSql: |
      SET execution.runtime-mode = streaming;
      SET 'state.checkpoints.dir' = 'file:///tmp/flink-checkpoints';
      SET 'state.savepoints.dir' = 'file:///tmp/flink-savepoints';
      SET 'execution.checkpointing.interval' = '3s';
      SET 'execution.checkpointing.mode' = 'EXACTLY_ONCE';

      CREATE TABLE t_k_orders (
        orderId          STRING,
        customerId       STRING,
        orderNumber      INT,
        product          STRING,
        backordered      BOOLEAN,
        cost             FLOAT,
        description      STRING,
        create_ts        BIGINT,
        creditCardNumber STRING,
        discountPercent  INT
      ) WITH (
        'connector' = 'kafka',
        'topic' = 'orders',
        'properties.bootstrap.servers' = 'kafka:9092',
        'scan.startup.mode' = 'earliest-offset',
        'format' = 'json'
      );

      CREATE TABLE t_i_orders (
        orderId          STRING,
        customerId       STRING,
        orderNumber      INT,
        product          STRING,
        backordered      BOOLEAN,
        cost             FLOAT,
        description      STRING,
        create_ts        BIGINT,
        creditCardNumber STRING,
        discountPercent  INT
      ) WITH (
        'connector' = 'iceberg',
        'catalog-type'='hive',
        'catalog-name'='dev',
        'warehouse' = 's3a://warehouse/',
        'hive-conf-dir' = '/opt/flink/conf'
      );

      CREATE TABLE t_k_pinot_sink (
        orderId   STRING,
        customerId STRING,
        product STRING,
        cost FLOAT,
        create_ts BIGINT
      ) WITH (
        'connector' = 'kafka',
        'topic' = 'pinot_orders_realtime',
        'properties.bootstrap.servers' = 'kafka:9092',
        'format' = 'json'
      );

      INSERT INTO t_i_orders
      SELECT *
      FROM t_k_orders
      WHERE cost > 100;

      INSERT INTO t_k_pinot_sink
      SELECT 
          orderId,
          customerId,
          product,
          cost,
          create_ts
      FROM t_k_orders
      WHERE cost > 100;

pinot:
  enabled: true
  image: apachepinot/pinot
  tag: "0.12.0"
  controllerPort: 9000
  brokerPort: 8099
  serverAdminPort: 8097
  zkImage: zookeeper
  zkTag: "3.8"
  zkPort: 2181

trino:
  enabled: true
  image: trinodb/trino
  tag: "435"
  port: 8080
  nodePort: 30890 # range between 30000 â€“ 32767

pyiceberg:
  enabled: true
  image: python
  tag: "3.12-bookworm"

ingress:
  enabled: false
  className: ""
  host: "data-platform.local"
