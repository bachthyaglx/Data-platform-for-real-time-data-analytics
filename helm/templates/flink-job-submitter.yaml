# ./flink-job-submitter.yaml (Đã tối ưu hóa với initContainer)
{{- if and .Values.flink.enabled .Values.flink.sqlJobs.enabled }}
# ========================== # Flink SQL Job Submitter # ========================== 
apiVersion: batch/v1
kind: Job
metadata:
  name: flink-sql-submitter
  namespace: {{ include "data-platform.namespace" . }}
  annotations:
    # Annotation để đảm bảo Job này được chạy lại sau khi triển khai hoặc nâng cấp (nếu cần)
    "helm.sh/hook": post-install,post-upgrade
    # "helm.sh/hook-delete-policy": before-hook-creation,hook-succeeded
spec:
  backoffLimit: 4
  template:
    metadata:
      labels:
        app: flink-sql-submitter
    spec:
      # Sử dụng một image nhẹ có kubectl (như bitnami/kubectl hoặc k8s.gcr.io/hyperkube) để chờ đợi
      # Nếu bạn đang dùng K3d/Minikube, image này thường có sẵn hoặc bạn có thể dùng Alpine/Curl.
      # Tuy nhiên, cách đáng tin cậy nhất là dùng kubectl.
      initContainers:
        - name: wait-for-flink-ready
          image: bitnami/kubectl:latest # Image chứa binary kubectl
          imagePullPolicy: IfNotPresent
          env:
            - name: NAMESPACE
              value: {{ include "data-platform.namespace" . }}
          command: ["/bin/bash", "-c"]
          args:
            - |
              echo "Waiting for flink-jobmanager (Deployment) to be ready..."
              # Chờ JobManager Deployment sẵn sàng (tối đa 120s)
              kubectl wait --for=condition=Available deployment/flink-jobmanager -n $NAMESPACE --timeout=120s
              
              echo "Waiting for flink-taskmanager (Deployment) to be ready..."
              # Chờ TaskManager Deployment sẵn sàng (tối đa 120s)
              kubectl wait --for=condition=Available deployment/flink-taskmanager -n $NAMESPACE --timeout=120s
              
              echo "Flink cluster is ready. Proceeding with job submission."
      
      restartPolicy: OnFailure 
      serviceAccountName: default # Đảm bảo Job Pod có quyền chạy kubectl wait (nếu không tạo ServiceAccount riêng)
      containers:
        - name: sql-submitter
          image: "{{ .Values.flink.image }}:{{ .Values.flink.tag }}" 
          imagePullPolicy: {{ .Values.flink.pullPolicy }}
          # Lệnh submit job
          args: ["sql-client.sh", "-f", "/opt/flink/jobs/kafka-to-iceberg.sql", "-s", "auto-submitted-session"]
          env:
            - name: FLINK_CONF_DIR 
              value: /opt/flink/conf
            - name: FLINK_PROPERTIES
              value: |
                rest.address: flink-jobmanager
                rest.port: {{ .Values.flink.jobManager.port }}
          volumeMounts:
            - name: hive-conf 
              mountPath: /opt/flink/conf/hive-site.xml 
              subPath: hive-site.xml
            - name: flink-sql 
              mountPath: /opt/flink/jobs/kafka-to-iceberg.sql 
              subPath: kafka-to-iceberg.sql
      volumes:
        - name: hive-conf
          configMap: 
            name: hive-site-xml
        - name: flink-sql
          configMap: 
            name: flink-sql-jobs
{{- end }}